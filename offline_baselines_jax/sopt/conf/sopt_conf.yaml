memo: xxx

seed: 1
img_shape: 128
vae_path: /workspace/jaxlog/model/prior_vae/normalize255-subgoal3-epoch3

# Maze Env
env_name: maze2d-randMaze0S${rand_maze_size}-ac-v0
rand_maze_size: 12
agent_centric: False
img_based: False
reward_type: dense
coverage_frac: 0.0

# Filename
filename_head: /workspace/soptlog
filename_tail: ${env_name}/seed${seed}-intrcoef${intrinsic_rew_coef}

tensorboard_log: ${filename_head}/tensorboard/${filename_tail}
model_path: ${filename_head}/model/${filename_tail}

# Hyperparams
model_type: PGIS_SAC
dropout: 0.0
learning_rate: 1e-4
replay_buffer_class: offline_baselines_jax.sopt.utils.PosGoalReplayBuffer
intrinsic_rew_coef: 10.0

# Models
pgis_model:
  _target_: offline_baselines_jax.sopt.PosGoalImgSubgoalSAC
  seed: ${seed}
  verbose: 1
  batch_size: 16
  tensorboard_log: ${tensorboard_log}-pgis
  buffer_size: 100_000
  train_freq: 1
  without_exploration: False
  learning_starts: 100
  dropout: ${dropout}
  intrinsic_rew_coef: ${intrinsic_rew_coef}
  policy_kwargs:
    dropout: ${dropout}
    latent_dim: 32
    goal_dim: 2

sac_model:
  _target_: offline_baselines_jax.SAC
  seed: ${seed}
  verbose: 1
  batch_size: 256
  tensorboard_log: ${tensorboard_log}-sac
  buffer_size: 100_000
  train_freq: 1
  without_exploration: False
  learning_starts: 100

# Learning Config
pgis_learning_kwargs:
  total_timesteps: 1_000_000
  log_interval: 1
  tb_log_name: PgisSAC

sac_learning_kwargs:
  total_timesteps: 10_000
  log_interval: 1

# Vae Model
vae_model:
  _target_: offline_baselines_jax.sopt.CondVaeGoalGenerator
  recon_dim: ${img_shape}
  latent_dim: 10
  dropout: ${dropout}
  kernel_size: 3
  strides: 2
  features:
    - 16
    - 32
    - 64
    - 32
    - 16